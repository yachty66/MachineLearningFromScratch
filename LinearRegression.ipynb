{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Linear Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Questions:\n",
    "\n",
    "### What is the wikipedia link to the algorithm?\n",
    "\n",
    "- https://en.wikipedia.org/wiki/Linear_regression\n",
    "\n",
    "### Which type of machine learning algorithm is this?\n",
    "\n",
    "- Supervised learning\n",
    "\n",
    "### What is the best video tutorial on this algorithm?\n",
    "\n",
    "- [Video](https://www.youtube.com/watch?v=ZkjP5RJLQF4)\n",
    "\n",
    "### What is the best picture which describes the algorithm?\n",
    "\n",
    "- ![Linear Regression](Images/LinearRegression.jpeg)\n",
    "\n",
    "### What is one case for which the algorithm is used for?\n",
    "\n",
    "- Company has saved sales data. If she does a linear regression with monthly sales and sales data the company can be eventually able to predict future sales."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sample data on which the algorithm gets proofed on:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "choosing a pytorch model and than reimplementing this with vanilla python. Use scikit learn because its easier to use. I am a little bit stuck on that - need to come back to this"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$y= \\theta_0 + \\theta_1 \\cdot x_1 + \\theta_2 \\cdot x_2 + \\cdots + \\theta_n \\cdot x_n$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$y =$ Dependent variable\n",
    "\n",
    "$\\theta_0$ = y intercept\n",
    "\n",
    "$\\theta_n= $ Slope coefficient \n",
    "\n",
    "$x_n=$ Independent variables "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## From scratch implementation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Steps for reproducing the algorithm:\n",
    "1. **Hypothesis**\n",
    "    - finding the best theta values a\n",
    "    - what are the best start parameter for linear regression - just start with one (is also something which I can figure out later through testing)\n",
    "    - input is y and X (multiple variables)\n",
    "    - function does calculate \n",
    "    - hypothesis returns y and gets x and thetas as an input X is numpy array\n",
    "2. **Cost function** \n",
    "    - defines the difference between the predicted y and and the actual y \n",
    "    - root mean squared error is used for that\n",
    "3. **Gradient descent**\n",
    "4. **Linear regression**\n",
    "\n",
    "later compare result to https://www.geeksforgeeks.org/gradient-descent-in-linear-regression/ at botton?\n",
    "\n",
    "This steps need to be inputted into a final linear rgeression method \n",
    "\n",
    "I was stuck with my implementation. How can I porceed futher with success. I really need to clarify each term. And it would be good to be already sure on how to implement the whole algorithm. Should I go with the hundred page machine learning book or should i create my own links for good sources?\n",
    "\n",
    "in the last step i need to compress everything in one method. this eg linear regression model which return first y with given data  than differences between real and predicted. i am not sure. mathmatically my goal is it to get the fit values of theta values. Because than i can calculate with X input every y."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hypothesis\n",
    "\n",
    "$y= \\theta_1 \\cdot x_1 + \\theta_2 \\cdot x_2 + \\cdots + \\theta_n \\cdot x_n$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#returns y this does mean that I either hava a cosntructr with which i change theta values globally or variables\n",
    "#single input x \n",
    "def hypothesis(X, thetas):\n",
    "    #how the data looks like:\n",
    "    #X = [[1,2,3], [1,2,3], [1,2,3], [1,2,3], [1,2,3]]\n",
    "    #thetas = [1,2,3]\n",
    "    '''version if several inputs for x \n",
    "    y=[]\n",
    "    for i in range(len(X)):\n",
    "        y = thetas[0] + sum(thetas[1:] * X[i])\n",
    "    return y'''    \n",
    "    '''version if one input for x \n",
    "    y = thetas[0] + sum(thetas[1:] * X)\n",
    "    return y'''\n",
    "    #inspired by https://ml-cheatsheet.readthedocs.io/en/latest/linear_regression.html#multivariable-regression\n",
    "    #can't multiply sequence by non-int of type 'list'\n",
    "    print(thetas)\n",
    "    print(X)\n",
    "    y = np.dot(thetas, X)\n",
    "    return y "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cost function\n",
    "\n",
    "$J = \\frac{1}{2n}\\sum_{i=1}^{n}(y_i - (\\theta_1 \\cdot x_1 + \\theta_2 \\cdot x_2 + \\cdots + \\theta_n \\cdot x_n))^2$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#calc error of all tuples (X,y) N \n",
    "#for that the function needs theta values, for hypothesis, X values for hypothesis and y values for comparing \n",
    "def costFunction(thetas, X, y):\n",
    "    sumVal = 0\n",
    "    for i in range(len(X)):\n",
    "        sumVal = sumVal + (y[i] - hypothesis(X[i], thetas))**2\n",
    "    j = 1/2*len(X) * sumVal\n",
    "    return j\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gradient descent\n",
    "\n",
    "Using chain rule for creating partial derivative of each $\\theta$.\n",
    "\n",
    "$f'(\\theta_1) = -x_1(y - (\\theta_1 x_1 + \\theta_2 x_2 + \\cdots + \\theta_n x_n)) \\\\$\n",
    "$f'(\\theta_2) = -x_2(y - (\\theta_1 x_1 + \\theta_2 x_2 + \\cdots + \\theta_n x_n)) \\\\$\n",
    "$\\vdots\\\\$\n",
    "$f'(\\theta_n) = -x_3(y - (\\theta_1 x_1 + \\theta_2 x_2 + \\cdots + \\theta_n x_n))$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def updateTheta(thetas,X, y, learningRate):\n",
    "    #have thetas and need to adjust them so that they fit the best line. first i calc y with an weights all initiliazed with 1 and get prob an huge error. dann muss ich solange weights verändern bis der error sich nicht mehr verändert.\n",
    "    #this does mean i need to calculate the old theta - the new theta. I dont need a learning raet for that thats just something for speeding things up.\n",
    "    #iter over all thetas and get new theta value for every theta and store in list \n",
    "    thetasNew = []\n",
    "\n",
    "    for i in thetas:\n",
    "        print(thetas[i])\n",
    "        print(learningRate)\n",
    "        print(-X[i])\n",
    "        print(y[i])\n",
    "        print(np.dot(X[i],thetas))\n",
    "        1\n",
    "0.01\n",
    "[-1 -2 -3 -5]\n",
    "2\n",
    "11\n",
    "\n",
    "            \n",
    "        #1 - 0.01 * ()\n",
    "        thetaNew = thetas[i] - learningRate*(-X[i](y[i]-(np.dot(X[i],thetas))))\n",
    "        thetasNew.append(thetaNew)\n",
    "    return thetaNew"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#now implementing all steps for creating a model to use\n",
    "#need some sample data for the model\n",
    "#with setted values build model\n",
    "\n",
    "def linearRegression(X, y, thetas, iterations, learningRate):\n",
    "    '''\n",
    "    1. Get first y \n",
    "    2. \n",
    "    '''\n",
    "    costFunctionResults = []\n",
    "    thetasResults = []\n",
    "    for i in range(iterations):\n",
    "        for i in range(len(X)):\n",
    "            j = costFunction(thetas, X, y)\n",
    "            thetas = updateTheta(thetas, X, y, learningRate)\n",
    "            costFunctionResults.append(j)\n",
    "            thetasResults.append(thetas)\n",
    "    return costFunctionResults, thetasResults\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 1 1 1]\n",
      "[1 2 3 4]\n",
      "[1 1 1 1]\n",
      "[1 2 3 5]\n",
      "[1 1 1 1]\n",
      "[1 2 4 4]\n",
      "[1 1 1 1]\n",
      "[3 5 6 6]\n",
      "[1 1 1 1]\n",
      "[5 7 8 9]\n",
      "1\n",
      "0.01\n",
      "[-1 -2 -3 -5]\n",
      "2\n",
      "11\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "'numpy.ndarray' object is not callable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/Users/maxhager/Projects2022/MachineLearningFromScratch/LinearRegression.ipynb Cell 17\u001b[0m in \u001b[0;36m<cell line: 6>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/maxhager/Projects2022/MachineLearningFromScratch/LinearRegression.ipynb#X63sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m iterations \u001b[39m=\u001b[39m \u001b[39m500\u001b[39m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/maxhager/Projects2022/MachineLearningFromScratch/LinearRegression.ipynb#X63sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m learningRate \u001b[39m=\u001b[39m \u001b[39m0.01\u001b[39m\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/maxhager/Projects2022/MachineLearningFromScratch/LinearRegression.ipynb#X63sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m linearRegression(X, y, thetas, iterations, learningRate)\n",
      "\u001b[1;32m/Users/maxhager/Projects2022/MachineLearningFromScratch/LinearRegression.ipynb Cell 17\u001b[0m in \u001b[0;36mlinearRegression\u001b[0;34m(X, y, thetas, iterations, learningRate)\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/maxhager/Projects2022/MachineLearningFromScratch/LinearRegression.ipynb#X63sZmlsZQ%3D%3D?line=11'>12</a>\u001b[0m \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(iterations):\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/maxhager/Projects2022/MachineLearningFromScratch/LinearRegression.ipynb#X63sZmlsZQ%3D%3D?line=12'>13</a>\u001b[0m     j \u001b[39m=\u001b[39m costFunction(thetas, X, y)\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/maxhager/Projects2022/MachineLearningFromScratch/LinearRegression.ipynb#X63sZmlsZQ%3D%3D?line=13'>14</a>\u001b[0m     thetas \u001b[39m=\u001b[39m updateTheta(thetas, X, y, learningRate)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/maxhager/Projects2022/MachineLearningFromScratch/LinearRegression.ipynb#X63sZmlsZQ%3D%3D?line=14'>15</a>\u001b[0m     costFunctionResults\u001b[39m.\u001b[39mappend(j)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/maxhager/Projects2022/MachineLearningFromScratch/LinearRegression.ipynb#X63sZmlsZQ%3D%3D?line=15'>16</a>\u001b[0m     thetasResults\u001b[39m.\u001b[39mappend(thetas)\n",
      "\u001b[1;32m/Users/maxhager/Projects2022/MachineLearningFromScratch/LinearRegression.ipynb Cell 17\u001b[0m in \u001b[0;36mupdateTheta\u001b[0;34m(thetas, X, y, learningRate)\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/maxhager/Projects2022/MachineLearningFromScratch/LinearRegression.ipynb#X63sZmlsZQ%3D%3D?line=9'>10</a>\u001b[0m     \u001b[39mprint\u001b[39m(y[i])\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/maxhager/Projects2022/MachineLearningFromScratch/LinearRegression.ipynb#X63sZmlsZQ%3D%3D?line=10'>11</a>\u001b[0m     \u001b[39mprint\u001b[39m(np\u001b[39m.\u001b[39mdot(X[i],thetas))\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/maxhager/Projects2022/MachineLearningFromScratch/LinearRegression.ipynb#X63sZmlsZQ%3D%3D?line=12'>13</a>\u001b[0m     thetaNew \u001b[39m=\u001b[39m thetas[i] \u001b[39m-\u001b[39m learningRate\u001b[39m*\u001b[39m(\u001b[39m-\u001b[39mX[i](y[i]\u001b[39m-\u001b[39;49m(np\u001b[39m.\u001b[39;49mdot(X[i],thetas))))\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/maxhager/Projects2022/MachineLearningFromScratch/LinearRegression.ipynb#X63sZmlsZQ%3D%3D?line=13'>14</a>\u001b[0m     thetasNew\u001b[39m.\u001b[39mappend(thetaNew)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/maxhager/Projects2022/MachineLearningFromScratch/LinearRegression.ipynb#X63sZmlsZQ%3D%3D?line=14'>15</a>\u001b[0m \u001b[39mreturn\u001b[39;00m thetaNew\n",
      "\u001b[0;31mTypeError\u001b[0m: 'numpy.ndarray' object is not callable"
     ]
    }
   ],
   "source": [
    "X = np.array([[1,2,3,4], [1,2,3,5], [1,2,4,4], [3,5,6,6], [5,7,8,9]])\n",
    "y = np.array([1,2,3,4,5])\n",
    "thetas = np.array([1,1,1,1])\n",
    "iterations = 500\n",
    "learningRate = 0.01\n",
    "linearRegression(X, y, thetas, iterations, learningRate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n"
     ]
    }
   ],
   "source": [
    "sexualActiviyWithWomans = 0 \n",
    "sexualActiviyWithMens = 3 \n",
    "bi = sexualActiviyWithMens/sexualActiviyWithMens\n",
    "print(bi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "i ask myself how i can get the value from b. i mean thats the output value of the regression. I need a learning rate and backpropagation for that because otherwise. \n",
    "I need to start with some value. \n",
    "\n",
    "'''\n",
    "\n",
    "#house prize = ? + floors\n",
    "def linearRegression(y, X):\n",
    "    for i in range(len(X)):\n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implementation with PyTorch"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.6 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
